{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# User-defined modules:\n",
    "import fluidmechanics as fluids\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrections for heliox flowrates (DataFrame 'H')\n",
    "The flowmeter used in the experiments (TSI) does not have a built in setting for heliox. The vendor recommended a correction factor to use while using heliox while the flowmeter was set for 'Air'. This correction factor turned out to be erroneous when testing with an Alicat flow controller, which had been validated. In order to shift all the heliox measurement flowrate to their proper values, a table of points showing the reading on the Alicat controller (correct) and the simultaneous reading on the TSI flow meter (incorrect) were recorded (in `HELIOX_FLOWRATE_CONVERT.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CORRECTIONS FOR ERRONEOUS HELIOX READINGS\n",
    "H = pd.read_csv(\"./SOURCE_DATA/SubjectReplicas_ExperimentalMeasurements/HELIOX_FLOWRATE_CONVERT.csv\")\n",
    "H = pd.pivot_table(H, index='alicatHeliumReading', aggfunc=(np.mean,np.std))  #aggregate and average repeated measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT HELIOX FLOW RATES\n",
    "def helioxcorrection(q,H):\n",
    "    TSI_Q  = H.loc[:,('tsiAirReading','mean')]\n",
    "    TRUE_Q = H.loc[:,('actualHelioxFlowRate','mean')]\n",
    "    return np.interp(q, TSI_Q, TRUE_Q)\n",
    "\n",
    "def correcthelioxflowrates(df,H):\n",
    "    df.loc[df['fluid']=='heliox', 'qstp'] = helioxcorrection(df.loc[df['fluid']=='heliox', 'qstp'], H)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental measurements (DataFrame 'T')\n",
    "Pressure drop measurements were done at various settings and recorded in `EXPERIMENT_DATA.csv`. The measurements were done for all combinations of:\n",
    "* fluid type (`fluid`): *air* or *heliox*\n",
    "* configuration (`config`): with the branching airway segment either *attached* or *detached*.\n",
    "* flow rates (`qstp`): 5-30 L/min for air, 7-45 L/min for heliox, recorded by the TSI meter for STP conditions\n",
    "* subject replicas (`subnum`): 10 child subjects numbered 2, 3, 5, 6, 9, 10, 11, 12, 13, 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT EXPERIMENTAL DATA\n",
    "T = pd.read_csv(\"./SOURCE_DATA/SubjectReplicas_ExperimentalMeasurements/EXPERIMENT_DATA.csv\")\n",
    "\n",
    "# rename headers, remove unneeded columns\n",
    "T = T.rename({'fluidFlag':'fluid', 'subNum':'subnum', 'attFlag':'config', 'Qstp':'qstp', 'PDrop':'pdrop'}, axis='columns')\n",
    "T = T.drop(columns=['date','dayRun','Tfluid','Pfluid'])\n",
    "\n",
    "# change fluid and configuration flags to actual descriptions\n",
    "T['fluid']  = T['fluid'].map( {1:'air', 2:'heliox'})\n",
    "T['config'] = T['config'].map({0:'detach', 1:'attach'})\n",
    "\n",
    "# correct all heliox flow rate readings to their proper values\n",
    "T = correcthelioxflowrates(T,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T[T['fluid']=='heliox'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute nominal flowrate (`qnom`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDE EACH READING INTO Q_NOMINAL GROUP USING 'DBSCAN'\n",
    "def assignqnomgroups(df,fluid):\n",
    "    qValues = df.loc[df['fluid']==fluid,'qstp'].values\n",
    "    qNomGroups = DBSCAN(min_samples=3).fit(qValues.reshape(-1,1)).labels_   # min samples set to 3 allows it to work for table E\n",
    "    df.loc[df['fluid']==fluid,'qnom'] = qNomGroups\n",
    "    return df\n",
    "\n",
    "T = assignqnomgroups(T,'air')          # attach\n",
    "T = assignqnomgroups(T,'heliox')\n",
    "T['qnom'] = T['qnom'].astype(int)  # convert index value to integer afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND AVERAGE QNOM VALUES FOR EACH QNOM GROUP\n",
    "def get_qnom_dict(df,fluid):\n",
    "    df_fluid = df.loc[df['fluid']==fluid, ['qnom','qstp']]      \n",
    "    df_groups = df_fluid.groupby(by='qnom').mean()                 # average of each nominal Q group\n",
    "    df_groups['qnom']=np.round(df_groups['qstp']).astype(int)    # convert qnom from float to int\n",
    "    df_groups = df_groups.drop(columns='qstp')                   # \n",
    "    df_groups_dict = df_groups.to_dict()\n",
    "    return df_groups_dict['qnom']\n",
    "\n",
    "# Assign mapping of qnom groups -> values to a master dectionary for both fluids\n",
    "QNOM_GROUPS_DICT_AIR = get_qnom_dict(T,'air')\n",
    "QNOM_GROUPS_DICT_HEL = get_qnom_dict(T,'heliox')\n",
    "QNOM_GROUPS_DICT = {'air':QNOM_GROUPS_DICT_AIR, 'heliox':QNOM_GROUPS_DICT_HEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QNOM_GROUPS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE QNOM GROUP INDICES WITH ACTUAL VALUES USING THE DICTIONARY\n",
    "def replace_qnom_groups_with_values(df,QNOM_GROUPS_DICT,fluid):\n",
    "    df.loc[df['fluid']==fluid,'qnom'] = df.loc[df['fluid']==fluid,'qnom'].map(QNOM_GROUPS_DICT[fluid])\n",
    "    return df\n",
    "\n",
    "T = replace_qnom_groups_with_values(T,QNOM_GROUPS_DICT,'air')\n",
    "T = replace_qnom_groups_with_values(T,QNOM_GROUPS_DICT,'heliox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = T.groupby(by=['fluid','config','subnum','qnom']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join attached and detached configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break table apart into 2 pieces for each configuration (attached, detached) \n",
    "def slicetable_on_config(T,config):\n",
    "    Tconfig = T[T['config']==config]\n",
    "    Tconfig = Tconfig.drop(columns=['config'])\n",
    "    return Tconfig\n",
    "\n",
    "Tattach = slicetable_on_config(T,'attach')\n",
    "Tdetach = slicetable_on_config(T,'detach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tables together based on fluid type, subject number and nominal flow rate\n",
    "T = pd.merge(Tattach, Tdetach,  how='left', left_on=['fluid','subnum','qnom'], right_on = ['fluid','subnum','qnom'])\n",
    "T = T.rename({'pdrop_x':'pdrop_attach', 'pdrop_y':'pdrop_detach'}, axis='columns')\n",
    "T = T.rename({'qstp_x' :'qstp_attach' , 'qstp_y' :'qstp_detach'},  axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average each flow rate reading to use as the flow rate\n",
    "qstp_list = ['qstp_attach','qstp_detach']\n",
    "T['qstp'] = T[qstp_list].mean(axis=1)\n",
    "T = T.drop(columns=qstp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns\n",
    "T = T[['fluid','subnum','qnom','qstp','pdrop_attach','pdrop_detach']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate $\\Delta P$ nose-throat and branching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sudden expansion pressure drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = pd.read_csv(\"./SOURCE_DATA/FLUID_VALUES.csv\")\n",
    "F = F.rename({'fluidName':'fluid', 'K_SE':'k_se','latexName':'latexname'}, axis='columns')\n",
    "F = F.drop(columns='fluidFlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.read_csv(\"./SOURCE_DATA/SubjectReplicas_AirwayDimensions/SUBJECT_VALUES.csv\")\n",
    "S = S.rename({'subNum':'subnum', 'areaAttach':'attacharea'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_df_small_to_big(df_big,df_small,indexname,propertyname,keepwhat='wholetable'):\n",
    "    '''map values of propertyname from a small df to a big df based on matching the indexname\n",
    "    df_big - destination data frame / df_small - source data frame /\n",
    "    indexname - column name to match between both tables / propertyname - value to map to bigger table based on smaller table'''\n",
    "    if isinstance(indexname,str): indexname = [indexname]\n",
    "    if isinstance(propertyname,str): propertyname = [propertyname]\n",
    "    property_df = df_small[indexname + propertyname]\n",
    "    df_aug =  pd.merge(df_big, property_df, how='left', left_on=indexname, right_on=indexname)\n",
    "    if keepwhat == 'wholetable':\n",
    "        return df_aug  #return whole table with new property values added\n",
    "    elif keepwhat == 'newvalue':\n",
    "        return df_aug[propertyname]  # or keep only the new property values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add necessary values to table for vector calculation of p_se, then drop them after. \n",
    "T = map_df_small_to_big(T,S,'subnum','attacharea')\n",
    "T = map_df_small_to_big(T,F,'fluid',['rho','mu','k_se'])\n",
    "\n",
    "def calc_pdrop_se(q_lpm, attacharea_m2, rho, k_se):\n",
    "    '''calculates sudden expansion into plenum \n",
    "    at the attachment point of replica'''\n",
    "    velattach = fluids.flow_to_vel(q_lpm, attacharea_m2)\n",
    "    pdrop_se = (1/2) * rho * k_se * (velattach**2)\n",
    "    return pdrop_se\n",
    "\n",
    "T['pdrop_se'] = calc_pdrop_se(T['qstp'].values, T['attacharea'].values, T['rho'].values, T['k_se'].values)\n",
    "T = T.drop(['attacharea','rho','mu','k_se'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import empty pressure drop readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "E = pd.read_csv(\"./SOURCE_DATA/SubjectReplicas_ExperimentalMeasurements/PDROP_EMPTY.csv\")\n",
    "\n",
    "# Rename columns and categories\n",
    "E = E.rename({'fluidFlag':'fluid', 'Qstp':'qstp', 'PDrop':'pdrop', 'attFlag':'config'}, axis='columns')\n",
    "E['fluid']  = E['fluid'].map( {1:'air', 2:'heliox'})\n",
    "\n",
    "# Correct erroneous heliox values\n",
    "E = correcthelioxflowrates(E,H)\n",
    "\n",
    "# Tag each reading with a qnom group\n",
    "E = assignqnomgroups(E,'air')\n",
    "E = assignqnomgroups(E,'heliox')\n",
    "E['qnom'] = E['qnom'].astype(int)\n",
    "\n",
    "# replace qnom groups by actual values using dictionary derived from table T\n",
    "E = replace_qnom_groups_with_values(E,QNOM_GROUPS_DICT,'air')\n",
    "E = replace_qnom_groups_with_values(E,QNOM_GROUPS_DICT,'heliox')\n",
    "\n",
    "# rearrange columns\n",
    "E = E[['fluid','qnom','qstp','pdrop']]\n",
    "assert all((np.abs(E.qnom - E.qstp)/E.qnom).values < 0.1), 'qnom assignment for table E failed'  # check that assignment of qnom worked\n",
    "\n",
    "# group repeated values done at the same flow rate \n",
    "E = pd.pivot_table(E, index=['fluid','qnom'], aggfunc=np.mean)  #aggregate and average repeated measurements \n",
    "E = E.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerfit(x,y):\n",
    "    ''' For form: y = a*x^b\n",
    "    Inputs:  (x, y) / Outputs: [a, b]'''\n",
    "    C = np.polyfit(np.log(x), np.log(y), 1);\n",
    "    a = np.exp(C[1]);\n",
    "    b = C[0];  \n",
    "    return a, b\n",
    "\n",
    "def make_pdrop_empty_lambda_for_fluid(E,fluid):\n",
    "    Etemp = E[E['fluid']==fluid]\n",
    "    a,b = powerfit(Etemp['qstp'].values, Etemp['pdrop'].values)\n",
    "    pdrop_empty_func = lambda q: a*(q**b)\n",
    "    return pdrop_empty_func\n",
    "\n",
    "def make_pdrop_empty_main_func(E):\n",
    "    functionList = []\n",
    "    uniqueFluids = E.fluid.unique()\n",
    "    for fluid in uniqueFluids:\n",
    "        functionList.append(make_pdrop_empty_lambda_for_fluid(E,fluid))\n",
    "    funcDict = dict(zip(uniqueFluids,functionList))\n",
    "    pdrop_empty_func = lambda q, fluid: funcDict[fluid](q)   # Return a function to calculate pdrop_empty based on only q and fluid\n",
    "    return pdrop_empty_func\n",
    "\n",
    "# Create a function to calculate pdrop_empty based on only q and fluid\n",
    "calc_pdrop_empty = make_pdrop_empty_main_func(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 'pdrop_empty' to account for the exit pipe dimensions\n",
    "T['pdrop_empty'] = np.vectorize(calc_pdrop_empty)(T.qstp,T.fluid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Branching and Nose-Throat pressure drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pdrop_dist and pdrop_nt as a function of the other recorded pressure drop values\n",
    "T['pdrop_branching'] = T['pdrop_attach'] - T['pdrop_detach'] + T['pdrop_se']\n",
    "T['pdrop_nosethroat'] = T['pdrop_detach'] - T['pdrop_se'] - T['pdrop_empty']\n",
    "T = T.drop(['pdrop_attach','pdrop_detach','pdrop_se','pdrop_empty'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reynolds number ($Re$) and Coefficient of Friction ($C_F$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add necessary values to main table in preparation for calculations\n",
    "T = map_df_small_to_big(T,S,'subnum','diam')\n",
    "T = map_df_small_to_big(T,F,'fluid',['rho','mu'])    \n",
    "\n",
    "# Calculate C_F and Re and add to main table\n",
    "T['cf_branching']  = fluids.calc_cf(T.pdrop_branching,  T.qstp, T.diam, T.rho)\n",
    "T['cf_nosethroat'] = fluids.calc_cf(T.pdrop_nosethroat, T.qstp, T.diam, T.rho)\n",
    "T['reynoldsnum']   = fluids.calc_reynoldsnum(T.qstp, T.diam, T.rho, T.mu)\n",
    "\n",
    "# Remove temporary calculation values\n",
    "T = T.drop(['diam','rho','mu'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYTICAL CALCULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T[(T.subnum==3) & (T.fluid=='heliox')]\n",
    "x.plot('reynoldsnum','cf_branching');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.figsize'] = [16,7]\n",
    "#uniqueFluids = T.fluid.unique()\n",
    "#uniqueSubnums = T.subnum.unique()\n",
    "#legendTitles = []\n",
    "#for fluid in uniqueFluids:\n",
    "#   for subnum in uniqueSubnums:\n",
    "#        dfx = T[(T.fluid==fluid) & (T.subnum==subnum)]\n",
    "#        plt.plot(dfx.qstp,dfx.pdrop_branching)\n",
    "#        legendTitles.append(fluid + ', ' + str(subnum))\n",
    "#plt.legend(legendTitles,loc='best')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_style('white')\n",
    "#colpal = sns.color_palette('pastel')\n",
    "#sns.relplot(x=\"qstp\", y=\"pdrop_branching\", data=T, col='fluid', hue='subnum', palette=colpal, markers='.', kind='line');\n",
    "#x=T.set_index(['fluid','qnom'],append=True)\n",
    "#x.unstack('fluid')\n",
    "#x.plot()2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO #\n",
    "- Change file hierarchy in folders\n",
    "- Combine base files with MATLAB so that both can work on the data at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fluids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluids.calc_pdrop_blasius(5,1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluids.calc_pdrop_modpedley(5,1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluids.calc_pdrop_pedley(5,1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in range(11):\n",
    "    print(gen, fluids.calc_pdrop_modpedley(10,10/1000,0.1,1.2,1.8e-5,gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_branching_airway_dimensions(subnum):\n",
    "    fpath = './SOURCE_DATA/SubjectReplicas_AirwayDimensions/'\n",
    "    fname = 'Sub' + str(subnum)\n",
    "    fext  = '.txt'\n",
    "    df = pd.read_csv(fpath + fname + fext, sep='\\t', \n",
    "                     names=['name','length_mm','diam_mm'])\n",
    "    df['diam_m'] = df.diam_mm / 1000\n",
    "    df['length_m'] = df.length_mm / 1000 \n",
    "    df['gen'] = df.name.str.replace('(\\d+).*', '\\g<1>').astype(int)\n",
    "    df = df.drop(columns=['diam_mm','length_mm'])\n",
    "    return df    \n",
    "\n",
    "def find_parents(df):\n",
    "    df['parent'] = (df.gen - 1).astype(str) + df.name.str.replace('^\\d+|.$','')\n",
    "    df['iparent'] = ''\n",
    "    for parent in df.parent[1:]:\n",
    "        df.loc[df.parent==parent, 'iparent'] = df.loc[df.name == parent].index[0]\n",
    "    return df\n",
    "\n",
    "def find_daughters(df):\n",
    "    daughternames = []\n",
    "    daughterindex = []\n",
    "    for name in a.name:\n",
    "        daughternames.append(a.loc[a.parent==name,'name'].values)\n",
    "        daughterindex.append(a.loc[a.parent==name].index.values)\n",
    "    df['daughters'] = daughternames\n",
    "    df['idaughters'] = daughterindex\n",
    "    return df\n",
    "\n",
    "a=import_branching_airway_dimensions(2)\n",
    "a=find_parents(a)\n",
    "a=find_daughters(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in a.daughters:\n",
    "    #print(x,type(x))\n",
    "    print(a.name[a.name.isin(x.tolist())].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=a.daughters[0].tolist()\n",
    "x in a.name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a.name.isin(['1a','1b'])].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.daughters.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
